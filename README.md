# Semantics Metrics Modeling Assistant

**An MCP agent that helps data teams define, validate, and visualize semantic metrics models with trust and observability built-in.**

## üéØ Overview

The Semantics Metrics Modeling Assistant is a Model Context Protocol (MCP) agent designed to reduce cognitive load for data teams working with semantic layers. It provides a conversational interface for defining metrics, visual feedback on lineage and dependencies, and trust indicators that help teams build confidence in their data.

## ‚ú® Key Features

### üó£Ô∏è Conversational Metric Definition
Define metrics naturally through conversation:
```
"Define 'Active Users' as daily unique logins"
"Create a metric for revenue per customer"
"What's the definition of our churn rate metric?"
```

### üìä Visual Lineage & Dependencies
- See how metrics relate to each other
- Understand upstream dependencies
- Track downstream impact of changes
- Identify circular dependencies

### üõ°Ô∏è Trust Indicators
Build confidence in your metrics with:
- **Freshness** - When was data last updated?
- **Test Coverage** - Are metrics validated?
- **Usage Stats** - How widely adopted is this metric?
- **Documentation Quality** - Is it well-documented?
- **Ownership** - Who maintains this metric?

### üîå Integration Support
Works with popular semantic layer tools:
- **dbt** - Metrics definitions and models
- **LookML** - Looker semantic models
- **YAML specs** - Standard metric definitions

## üåü Why This Matters

### The Problem
Data teams struggle with:
- **Metric sprawl** - 50 different "revenue" metrics
- **Trust issues** - "Which metric should I use?"
- **Cognitive overload** - Complex dependencies and lineage
- **Governance gaps** - No clear ownership or validation

### The Solution
This assistant provides:
- ‚úÖ **Reduced cognitive load** - Conversational interface over complex YAML
- ‚úÖ **Built-in trust** - Transparency into metric quality
- ‚úÖ **Governance guardrails** - Validation and ownership tracking
- ‚úÖ **Observability** - See how metrics are used and maintained

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Conversational Interface (MCP Tools)   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ define_metric()                      ‚îÇ
‚îÇ  ‚Ä¢ validate_metric()                    ‚îÇ
‚îÇ  ‚Ä¢ visualize_lineage()                  ‚îÇ
‚îÇ  ‚Ä¢ check_trust_score()                  ‚îÇ
‚îÇ  ‚Ä¢ search_metrics()                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Metric Repository                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Stores metric definitions            ‚îÇ
‚îÇ  ‚Ä¢ Tracks lineage and dependencies      ‚îÇ
‚îÇ  ‚Ä¢ Collects usage and quality metadata  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Data Source Integrations               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ dbt project files                    ‚îÇ
‚îÇ  ‚Ä¢ LookML models                        ‚îÇ
‚îÇ  ‚Ä¢ YAML metric specs                    ‚îÇ
‚îÇ  ‚Ä¢ SQL queries                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/jkelleman/semantics-metrics-modeling-assistant.git
cd semantics-metrics-modeling-assistant

# Install dependencies
uv add "mcp[cli]"
uv pip install -e .

# Run the agent
uv run python -m semantic_metrics.server
```

### Usage Examples

**Define a new metric:**
```python
define_metric(
    name="Active Users",
    description="Daily unique user logins",
    calculation="COUNT(DISTINCT user_id) WHERE login_date = CURRENT_DATE",
    owner="@data-team",
    tags=["engagement", "daily"]
)
```

**Check trust score:**
```python
check_trust_score("Active Users")

# Returns:
# Trust Score: 85/100
# ‚úÖ Freshness: Updated 2 hours ago
# ‚úÖ Test Coverage: 4 tests passing
# ‚ö†Ô∏è Usage: Low adoption (3 users)
# ‚úÖ Documentation: Complete
# ‚úÖ Owner: Assigned (@data-team)
```

**Visualize lineage:**
```python
visualize_lineage("Revenue per Customer")

# Returns:
# Revenue per Customer
#   ‚îú‚îÄ‚îÄ Total Revenue
#   ‚îÇ   ‚îú‚îÄ‚îÄ Order Amount (raw.orders)
#   ‚îÇ   ‚îî‚îÄ‚îÄ Refunds (raw.refunds)
#   ‚îî‚îÄ‚îÄ Customer Count
#       ‚îî‚îÄ‚îÄ Unique Customers (raw.users)
```

## üé® Design Principles

### 1. Conversational First
Complex YAML configurations become natural language conversations. Users shouldn't need to remember syntax.

### 2. Show, Don't Tell
Visual lineage graphs > text descriptions. Make dependencies and relationships immediately clear.

### 3. Trust Through Transparency
Display quality indicators upfront. Users should know what they can rely on.

### 4. Progressive Disclosure
Show basic info first, details on demand. Don't overwhelm with complexity.

### 5. Governance by Default
Make it easy to do the right thing (add owners, tests, docs). Make it hard to create orphaned metrics.

## üìã Use Cases

### Data Team Member
"I need to create a metric for customer lifetime value that everyone can trust."

**Assistant helps:**
- Define the metric in plain language
- Validate SQL logic
- Check for similar existing metrics
- Set up ownership and documentation
- Add to metric catalog

### Analytics Engineer
"Why is my dashboard showing different revenue numbers than finance?"

**Assistant helps:**
- Compare revenue metric definitions
- Show lineage and data sources
- Identify where definitions diverge
- Recommend canonical metric

### Data Leader
"Which metrics are most critical and need better governance?"

**Assistant helps:**
- Show metrics by usage and trust score
- Identify high-usage, low-trust metrics
- Track governance coverage
- Monitor metric health over time

## üîß Technical Stack

- **Python 3.10+** - Core language
- **FastMCP** - MCP protocol implementation
- **SQLAlchemy** - Database interactions
- **YAML/JSON** - Metric definitions
- **NetworkX** - Lineage graphs
- **Rich** - Terminal visualizations

## üõ†Ô∏è MCP Tools

### Core Tools

| Tool | Purpose | Example |
|------|---------|---------|
| `define_metric()` | Create new metric | Define "Active Users" |
| `validate_metric()` | Check metric validity | Validate SQL and logic |
| `search_metrics()` | Find existing metrics | Search for "revenue" |
| `visualize_lineage()` | Show dependencies | See metric relationships |
| `check_trust_score()` | Assess metric quality | Check trust indicators |
| `suggest_improvements()` | Recommend fixes | Improve metric quality |
| `compare_metrics()` | Compare definitions | Why do these differ? |
| `export_to_dbt()` | Generate dbt YAML | Create dbt metric file |

## üìö What This Demonstrates

### UX Skills
- **Cognitive Load Reduction** - Complex systems made simple
- **Trust Design** - Building confidence through transparency
- **Progressive Disclosure** - Information architecture for complexity
- **Conversational UI** - Natural language over configuration files

### Technical Skills
- **MCP Development** - Building production AI agents
- **Data Modeling** - Understanding semantic layers
- **System Design** - Governance and observability
- **Integration** - Working with dbt, LookML, and data tools

### Domain Expertise
- **Metrics Governance** - Ownership, validation, documentation
- **Data Lineage** - Dependency tracking and impact analysis
- **Data Observability** - Freshness, quality, usage metrics
- **Semantic Layers** - Modern data stack patterns

## üéì Why This Project Matters

As a **Principal Content Designer at Microsoft** working with data and AI systems, this project showcases:

1. **Deep understanding of data team challenges** - Metrics sprawl and trust issues are real problems
2. **UX for technical users** - Making complex systems accessible without oversimplifying
3. **Design for trust and observability** - Critical for enterprise data systems
4. **AI-augmented workflows** - Using MCP to enhance (not replace) human expertise

This is the kind of UX design that enterprise data teams need - making governance easy, trust visible, and complexity manageable.

## üë§ About

**Jen Kelleman**  
Principal Content Designer @ Microsoft

Passionate about designing AI and data experiences that reduce cognitive load and build trust.

### Connect
- üíº [LinkedIn](https://linkedin.com/in/jenniferkelleman)
- ‚úçÔ∏è [Medium](https://jenkelleman.medium.com)
- üåê [AI Content Design Handbook](https://jkelleman.github.io/ai-content-design-handbook/)
- üìß jenkelleman@microsoft.com

### Other Projects
- **[MCP-Oreilly](https://github.com/jkelleman/MCP-Oreilly)** - Three production MCP agents for real-world workflows
- **[AI Content Design Handbook](https://github.com/jkelleman/ai-content-design-handbook)** - Comprehensive UX writing guide for AI

---

**Making data governance human-centered, one metric at a time.**
